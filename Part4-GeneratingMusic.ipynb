{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c916be9-186a-427f-9407-5348f75af17b",
   "metadata": {},
   "source": [
    "### Generating music using the model trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15dbbb6-f899-4f09-978f-b18a14cc77ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'cfg', 'vocab_size'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "ckpt = torch.load(r\"C:\\Users\\shash\\Downloads\\large_model_trained_8.pt\", map_location=\"cpu\")\n",
    "print(ckpt.keys() if isinstance(ckpt, dict) else type(ckpt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413ee1af-f906-4fa9-abe0-7945525b4799",
   "metadata": {},
   "source": [
    "So we loaded the trained large model that we had, now, we will get the exact model on which it was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c85c0e-68fc-4b89-8c4d-eb68ee781de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GPTConfig:\n",
    "    def __init__(self, vocab_size, block_size,\n",
    "                 n_layer, n_head, n_embd):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.block_size = block_size\n",
    "        self.n_layer = n_layer\n",
    "        self.n_head = n_head\n",
    "        self.n_embd = n_embd\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        self.n_head = config.n_head\n",
    "        self.head_dim = config.n_embd // config.n_head\n",
    "        self.scale = 1.0 / (self.head_dim ** 0.5)\n",
    "\n",
    "        self.qkv = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
    "        self.proj = nn.Linear(config.n_embd, config.n_embd)\n",
    "        self.register_buffer(\"mask\",\n",
    "            torch.tril(torch.ones(config.block_size, config.block_size))\n",
    "            .view(1, 1, config.block_size, config.block_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "\n",
    "        qkv = self.qkv(x)\n",
    "        q, k, v = qkv.split(C, dim=2)\n",
    "        q = q.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(B, T, self.n_head, self.head_dim).transpose(1, 2)\n",
    "        att = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        att = att.masked_fill(self.mask[:, :, :T, :T] == 0, float(\"-inf\"))\n",
    "        att = att.softmax(dim=-1)\n",
    "\n",
    "        out = att @ v\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
    "        out = self.proj(out)\n",
    "        return out\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(config.n_embd, 4 * config.n_embd)\n",
    "        self.fc2 = nn.Linear(4 * config.n_embd, config.n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(F.gelu(self.fc1(x)))\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config: GPTConfig):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(config.n_embd)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.ln2 = nn.LayerNorm(config.n_embd)\n",
    "        self.ff = FeedForward(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, n_layer, n_head, n_embd):\n",
    "        super().__init__()\n",
    "        cfg = GPTConfig(vocab_size, block_size, n_layer, n_head, n_embd)\n",
    "        self.cfg = cfg\n",
    "\n",
    "        self.token_emb = nn.Embedding(cfg.vocab_size, cfg.n_embd)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, cfg.block_size, cfg.n_embd))\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "\n",
    "        self.blocks = nn.ModuleList([Block(cfg) for _ in range(cfg.n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(cfg.n_embd)\n",
    "        self.head = nn.Linear(cfg.n_embd, cfg.vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.size()\n",
    "        assert T <= self.cfg.block_size, \"Sequence is too long for training\"\n",
    "\n",
    "        tok = self.token_emb(idx)\n",
    "        pos = self.pos_emb[:, :T, :]\n",
    "        x = self.drop(tok + pos)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.head(x)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            loss = F.cross_entropy(\n",
    "                logits.view(-1, logits.size(-1)),\n",
    "                targets.view(-1)\n",
    "            )\n",
    "        return logits, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97b0f966-6c37-4750-a151-4dbd0377a9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'cfg', 'vocab_size'])\n"
     ]
    }
   ],
   "source": [
    "print(torch.load(r\"C:\\Users\\shash\\Downloads\\large_model_trained_8.pt\", map_location=\"cpu\").keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95222d85-bdca-4bc0-aa35-111a3b990e82",
   "metadata": {},
   "source": [
    "Our next step is to get the vocabulary data and analyse it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "077b500e-807d-4f39-8ca1-f66a5c9abdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'list'>\n",
      "Length: 8002\n",
      "First 30 tokens: ['<PAD>', '<UNK>', '-', '|', 'z', '\\\\', '2', '/', '496', '[', ']', '8', 'B', 'b', '428', '232', 'C,,', 'z119', 'C', 'D', '244', '500', 'A', 'G,', 'A,', 'G', 'E', '504', 'F', 'z8']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = json.load(open(r\"C:\\Users\\shash\\Downloads\\vocab (2).json\"))\n",
    "\n",
    "vocab_list = data[\"vocab\"]           # this is a list\n",
    "print(\"Type:\", type(vocab_list))\n",
    "print(\"Length:\", len(vocab_list))\n",
    "print(\"First 30 tokens:\", vocab_list[:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd4e980f-bf5f-4ea6-a346-427a88b06aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = data[\"vocab\"]\n",
    "\n",
    "itos = vocab\n",
    "stoi = {tok: i for i, tok in enumerate(vocab)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea782c05-66d9-4547-8718-99afa14cc74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "cfg = ckpt[\"cfg\"]\n",
    "vocab_size = len(vocab)\n",
    "block_size = cfg[\"block_size\"]\n",
    "n_layer = cfg[\"n_layer\"]\n",
    "n_head = cfg[\"n_head\"]\n",
    "n_embd = cfg[\"n_embd\"]\n",
    "model = GPT(\n",
    "    vocab_size,\n",
    "    block_size,\n",
    "    n_layer,\n",
    "    n_head,\n",
    "    n_embd\n",
    ")\n",
    "\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a422a44-94a2-492f-b9f8-b12802d78796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next(logits, temperature=1.0, top_k=50, pad_id=None):\n",
    "    logits = logits[:, -1, :] / temperature\n",
    "\n",
    "    # top-k filtering\n",
    "    if top_k is not None:\n",
    "        values, indices = torch.topk(logits, top_k)\n",
    "        filtered = torch.full_like(logits, float('-inf'))\n",
    "        filtered.scatter_(1, indices, values)\n",
    "        logits = filtered\n",
    "\n",
    "    # Suppress PAD entirely\n",
    "    if pad_id is not None:\n",
    "        logits[0, pad_id] = float('-inf')\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    next_id = torch.multinomial(probs, 1)\n",
    "    return next_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58dacba1-1623-41fb-9341-764dffc9649f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 100/500 tokens\n",
      "Generated 200/500 tokens\n",
      "Generated 300/500 tokens\n",
      "Generated 400/500 tokens\n",
      "Generated 500/500 tokens\n"
     ]
    }
   ],
   "source": [
    "generated = []\n",
    "seed_tok = \"K:C\"\n",
    "idx = torch.tensor([[stoi[seed_tok]]], dtype=torch.long)\n",
    "N = 500\n",
    "for i in range(N):\n",
    "    if idx.size(1) > block_size:\n",
    "        idx = idx[:, -block_size:]\n",
    "\n",
    "    logits, _ = model(idx)\n",
    "\n",
    "    next_id = sample_next(\n",
    "        logits,\n",
    "        temperature=1.0,\n",
    "        top_k=50,\n",
    "        pad_id=pad_id\n",
    "    )\n",
    "\n",
    "    idx = torch.cat([idx, next_id], dim=1)\n",
    "    tok = itos[next_id.item()]\n",
    "    if tok != \"<PAD>\":\n",
    "        generated.append(tok)\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(f\"Generated {i + 1}/{N} tokens\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1a7b5-8277-46f2-9742-2a373ec51263",
   "metadata": {},
   "source": [
    "Here we are able to generate the tokens and are able to visulize them, We would need to clean this data for some random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff366959-378e-4ef8-b6c1-5cf59b5ed7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D,',\n",
       " '2',\n",
       " '8',\n",
       " 'b',\n",
       " 'F,,',\n",
       " '|',\n",
       " '|',\n",
       " 'z2',\n",
       " '/',\n",
       " 'b',\n",
       " 'z',\n",
       " '/',\n",
       " '-',\n",
       " '\\\\',\n",
       " '-',\n",
       " '-',\n",
       " 'z',\n",
       " '\\\\',\n",
       " '/',\n",
       " '232']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13f22a44-9df4-4807-be9d-f3b1c44f369e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\shash\\anaconda3\\lib\\site-packages (2.9.0+cu126)\n",
      "Collecting music21\n",
      "  Downloading music21-9.9.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\shash\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shash\\anaconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: chardet in c:\\users\\shash\\anaconda3\\lib\\site-packages (from music21) (4.0.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\shash\\anaconda3\\lib\\site-packages (from music21) (1.4.2)\n",
      "Collecting jsonpickle (from music21)\n",
      "  Downloading jsonpickle-4.1.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\shash\\anaconda3\\lib\\site-packages (from music21) (3.10.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\shash\\anaconda3\\lib\\site-packages (from music21) (10.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.4 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from music21) (2.2.6)\n",
      "Requirement already satisfied: requests in c:\\users\\shash\\anaconda3\\lib\\site-packages (from music21) (2.32.3)\n",
      "Collecting webcolors>=1.5 (from music21)\n",
      "  Downloading webcolors-25.10.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from matplotlib->music21) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from matplotlib->music21) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from matplotlib->music21) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from matplotlib->music21) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from matplotlib->music21) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from matplotlib->music21) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from matplotlib->music21) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from matplotlib->music21) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->music21) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from requests->music21) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from requests->music21) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from requests->music21) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shash\\anaconda3\\lib\\site-packages (from requests->music21) (2025.10.5)\n",
      "Downloading music21-9.9.1-py3-none-any.whl (20.1 MB)\n",
      "   ---------------------------------------- 0.0/20.1 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 3.9/20.1 MB 25.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 13.4/20.1 MB 35.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 20.1/20.1 MB 37.2 MB/s eta 0:00:00\n",
      "Downloading webcolors-25.10.0-py3-none-any.whl (14 kB)\n",
      "Downloading jsonpickle-4.1.1-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: webcolors, jsonpickle, music21\n",
      "\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   -------------------------- ------------- 2/3 [music21]\n",
      "   ---------------------------------------- 3/3 [music21]\n",
      "\n",
      "Successfully installed jsonpickle-4.1.1 music21-9.9.1 webcolors-25.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch music21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c66a6593-68ab-4030-9b86-aae48a8b604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "from collections import Counter\n",
    "CKPT_PATH = r\"C:\\Users\\shash\\Downloads\\large_model_trained_8.pt\"\n",
    "VOCAB_PATH = r\"C:\\Users\\shash\\Downloads\\vocab (2).json\"\n",
    "OUT_ABC = \"generated.abc\"\n",
    "OUT_MID = \"generated.mid\"\n",
    "def sample_next(logits, temperature=1.0, top_k=50, pad_id=None):\n",
    "    \"\"\"\n",
    "    logits: (B, T, V)\n",
    "    returns: next_id tensor of shape (B, 1)\n",
    "    \"\"\"\n",
    "    logits = logits[:, -1, :] / max(1e-8, temperature)\n",
    "\n",
    "    if top_k is not None and top_k > 0:\n",
    "        values, indices = torch.topk(logits, top_k, dim=-1)\n",
    "        filtered = torch.full_like(logits, float(\"-inf\"))\n",
    "        filtered.scatter_(1, indices, values)\n",
    "        logits = filtered\n",
    "\n",
    "    if pad_id is not None:\n",
    "        logits[:, pad_id] = float(\"-inf\")\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    next_id = torch.multinomial(probs, num_samples=1)\n",
    "    return next_id\n",
    "def main():\n",
    "    data = json.load(open(VOCAB_PATH, \"r\", encoding=\"utf8\"))\n",
    "    if isinstance(data, dict) and \"vocab\" in data:\n",
    "        vocab_list = data[\"vocab\"]\n",
    "    elif isinstance(data, list):\n",
    "        vocab_list = data\n",
    "    else:\n",
    "        raise RuntimeError(\"Unexpected vocab.json structure. Should be list or { 'vocab': [...] }\")\n",
    "\n",
    "    itos = list(vocab_list)\n",
    "    stoi = {tok: i for i, tok in enumerate(itos)}\n",
    "    print(\"Vocab size:\", len(itos))\n",
    "    ckpt = torch.load(CKPT_PATH, map_location=\"cpu\")\n",
    "    assert \"model\" in ckpt and \"cfg\" in ckpt, \"checkpoint missing expected keys\"\n",
    "\n",
    "    cfg = ckpt[\"cfg\"]\n",
    "    vocab_size = len(itos)\n",
    "    block_size = cfg[\"block_size\"]\n",
    "    n_layer = cfg[\"n_layer\"]\n",
    "    n_head = cfg[\"n_head\"]\n",
    "    n_embd = cfg[\"n_embd\"]\n",
    "    try:\n",
    "        from model import GPT as GPT_Class\n",
    "    except Exception:\n",
    "        if \"GPT\" in globals():\n",
    "            GPT_Class = globals()[\"GPT\"]\n",
    "        else:\n",
    "            raise RuntimeError(\"GPT class not found. Put your GPT class in model.py or paste it above this script.\")\n",
    "    model = GPT_Class(vocab_size, block_size, n_layer, n_head, n_embd)\n",
    "    model.load_state_dict(ckpt[\"model\"])\n",
    "    model.eval()\n",
    "\n",
    "    pad_token = \"<PAD>\"\n",
    "    pad_id = stoi.get(pad_token, None)\n",
    "    print(\"PAD id:\", pad_id)\n",
    "    possible_seeds = [\"X:1\",\"K:C\",\"C\",\"^C\",\"G\",\"A\",\"B\"]\n",
    "    seed_tok = next((s for s in possible_seeds if s in stoi), None)\n",
    "    if seed_tok is None:\n",
    "        seed_tok = next((t for t in itos if t != pad_token), itos[0])\n",
    "    print(\"Using seed token:\", seed_tok)\n",
    "    idx = torch.tensor([[stoi[seed_tok]]], dtype=torch.long)\n",
    "    generated = []\n",
    "    idx = torch.tensor([[stoi[seed_tok]]], dtype=torch.long)\n",
    "    temperature=1.2\n",
    "    for i in range(N):\n",
    "        if idx.size(1) > block_size:\n",
    "            idx = idx[:, -block_size:]\n",
    "    \n",
    "        logits, _ = model(idx)\n",
    "    \n",
    "        next_id = sample_next(\n",
    "            logits,\n",
    "            temperature=temperature,\n",
    "            top_k=60,\n",
    "            pad_id=pad_id\n",
    "        )\n",
    "    \n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "        tok = itos[next_id.item()]\n",
    "        if tok != \"<PAD>\":\n",
    "            generated.append(tok)\n",
    "    \n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Generated {i + 1}/{N} tokens\")\n",
    "\n",
    "    body = \" \".join(generated)\n",
    "    header_lines = [\n",
    "        \"X:1\",\n",
    "        \"T:Generated by LLM\",\n",
    "        \"M:4/4\",\n",
    "        \"L:1/8\",\n",
    "        \"Q:1/4=120\",\n",
    "        \"K:C\"\n",
    "    ]\n",
    "    abc_text = \"\\n\".join(header_lines) + \"\\n\" + body + \"\\n\"\n",
    "    abc_text = abc_text.replace(\"%\", \"\")\n",
    "    abc_text = \" \".join(abc_text.split())\n",
    "    with open(OUT_ABC, \"w\", encoding=\"utf8\") as f:\n",
    "        f.write(abc_text)\n",
    "    print(\"Saved ABC to\", OUT_ABC)\n",
    "    print(\"ABC preview:\\n\", abc_text[:400], \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1bea6d15-5641-4957-8ff7-b1cee8128b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import music21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "969bc5df-92b8-4517-8bd5-b66a8606c17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "music21 conversion failed: invalid literal for int() with base 10: \"1 T:Generated by LLM M:4/4 L:1/8 Q:1/4=120 K:C g 2 - z - d - - | C,, - <UNK> [ 232 | - | - z - z - 8 [ | | ^A ^A,, z3 ^A \\\\ - z z3 z119 b z | - \\\\ - / \\\\ z3 4 z | <UNK> G, [ - - - ^a C,,, | - 8 2 e |\n",
      "You can inspect generated.abc and convert with abc2midi or music21 manually.\n",
      "Vocab size: 8002\n",
      "PAD id: 0\n",
      "Using seed token: K:C\n",
      "Generated 100/500 tokens\n",
      "Generated 200/500 tokens\n",
      "Generated 300/500 tokens\n",
      "Generated 400/500 tokens\n",
      "Generated 500/500 tokens\n",
      "Saved ABC to generated.abc\n",
      "ABC preview:\n",
      " X:1 T:Generated by LLM M:4/4 L:1/8 Q:1/4=120 K:C - 244 | 496 [ 2 / - z123 ^F, 8 2 8 | | - z2 3 4 \\ - ^a c z / - - E, - z \\ - / - - | ^C,, | | - \\ D,, [ 4 ^D, | / ^A,,, - \\ | - z \\ | | - / 428 b \\ - - - 2 c z \\ - | =C,, A, \\ 2 [ - 428 / - - z =A, z e | - / e' z2 [ - - - - - - ^D, ^A 500 504 / 496 program | | - d' - 232 ^A | C,, / - \\ - - - ( | | 232 ^A [ - [ \\ - z6 z119 | G, z z8 ^A F \\ | | ^A - d  ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "        from music21 import converter\n",
    "        score = converter.parse(OUT_ABC)\n",
    "        score.write(\"midi\", fp=OUT_MID)\n",
    "        print(\"Saved MIDI to\", OUT_MID)\n",
    "except Exception as e:\n",
    "        print(\"music21 conversion failed:\", e)\n",
    "        print(\"You can inspect\", OUT_ABC, \"and convert with abc2midi or music21 manually.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb410a-a12a-4ca7-a8da-b4210dd8fb56",
   "metadata": {},
   "source": [
    "Now we would be cleaning this data to get a proper music octaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5e93656e-3f08-4774-be8f-1b28841ea927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File fixed and saved as 'cleaned_music.abc'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "tokens = \"\"\"M:4/4 L:1/8 Q:1/4=120 K:C g 2 - z - d - - | C,, - <UNK> [ 232 | - | - z - z - 8 [ | | ^A ^A,, z3 ^A \\ - z z3 z119 b z | - \\ - / \\ z3 4 z | <UNK> G, [ - - - ^a C,,, | - 8 2 e | - | 2 z2 =A z \\ - - 4 z3 6 e | | - z [ - \\ - - z b z ^D,, \\ - - z4 e z b z - - ^a z - - 2 A d 232 - A,, ^d 428 x 8 - 8 8 8 8 6 ^D, | - 8 <UNK> | B,,, - <UNK> | - [ - - \\ | | - z a ^a =D,, [ - [ | - ^A,,, ( | - 232 ^F,, z119 - - 2 8 e' \\ | - | D | C,,, | =A, z119 z2 C,,, 492 \\ | d \\ - - - 2 =D - z8 0 - - e | - C,,, b z119 / G < - - z8 504 C,,, | 232 z123 | | | - 2 ( | ^D \\ | | - \\ - \\ 4 8 ^F,, e' C,,, | d [ \\ - \\ - 232 MIDI A, [ =D z123 - 6 3 | 8 z g 500 =D, [ 3 / 428 - - - z4 - - z3 428 g \\ | | - C,,, | - [ <UNK> 496 =A, ( | | - =A, E,,, [ : - n - =G, ^d [ / 428 3 - - =F, | - - - =a - - g B,,, D, n - - - - =F, 428 ' z119 =A | | - - ( | ] ] | G d ' B \\ - 4 496 e' ^A - - 4 8 ^F,, 8 <UNK> D,, - / D, - ^A,,, < - - - - - - \\ | | | - - - - z119 =B, =D, / 428 3 ^A 2 [ 6 8 z119 - 6 6 8 8 a E,,, [ | - ^A, b [ - | | - - - y | - - - ^A, g' [ - | - 6 3 \\ | | - [ =F,, | - y A | ^F,, ^D, | | f [ [ ^D, | | - ^A,, =A, \\ ] - 4 2 ^A,, ^D,,, z8 2 c z8 <UNK> B z8 - - - - - - [ / =D - ^A, 496 =G, a | - - - - - - - 232 \\ - - - - - - - - - - - - g \\ | =D, | D,, | =A, ^D,,, \\ \\ | - - - - g 8 8 - - - - - /\"\"\".split()\n",
    "\n",
    "def clean_and_fix(token_list):\n",
    "    headers = []\n",
    "    cleaned_body = []\n",
    "    header_pattern = re.compile(r'^[A-Z]:\\S+')\n",
    "    valid_music_pattern = re.compile(r\"^[A-Ga-gzZ\\^=_,'0-9/\\|\\[\\]-]+$\")\n",
    "\n",
    "    for tok in token_list:\n",
    "        tok = tok.strip()\n",
    "        if header_pattern.match(tok):\n",
    "            headers.append(tok)\n",
    "            continue\n",
    "        if tok in [\"<UNK>\", \"<PAD>\", \"MIDI\", \"n\", \"y\", \"x\", \"/\", \"//\", \"\\\\\", \"-\", \"--\", \"---\", \"'\", \"''\", \":\", \"[\", \"]\", \"(\", \")\"]:\n",
    "            continue\n",
    "        if tok.isdigit() and int(tok) > 16:\n",
    "            continue\n",
    "        if re.search(r\"[A-Ga-gz]\\d{3,}\", tok):\n",
    "            tok = re.sub(r\"\\d+\", \"\", tok)\n",
    "\n",
    "        if valid_music_pattern.match(tok):\n",
    "            cleaned_body.append(tok)\n",
    "    final_headers = []\n",
    "    has_x = any(h.startswith(\"X:\") for h in headers)\n",
    "    if not has_x:\n",
    "        final_headers.append(\"X:1\") \n",
    "    \n",
    "    final_headers.extend(headers)\n",
    "\n",
    "    return \"\\n\".join(final_headers) + \"\\n\" + \" \".join(cleaned_body)\n",
    "cleaned_abc = clean_and_fix(tokens)\n",
    "\n",
    "with open(\"cleaned_music.abc\", \"w\") as f:\n",
    "    f.write(cleaned_abc)\n",
    "\n",
    "print(\"File fixed and saved as 'cleaned_music.abc'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfd703e-8623-4024-914f-6da1211a7b89",
   "metadata": {},
   "source": [
    "This generated our cleaned music and now we would be converting the abc files to mid files using abc2midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f725e1f8-f519-4708-962f-20947e4e22c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 'cleaned_music.abc'\n",
      "Conversion Successful!\n",
      "4.49 February 21 2021 abc2midi\n",
      "Error in line-char 6-2 : Unrecognized character: 2\n",
      "Error in line-char 6-22 : Unrecognized character: 8\n",
      "Error in line-char 6-58 : Unrecognized character: 4\n",
      "Error in line-char 6-77 : Unrecognized character: 8\n",
      "Error in line-char 6-79 : Unrecognized character: 2\n",
      "Error in line-char 6-87 : Unrecognized character: 2\n",
      "Error in line-char 6-97 : Unrecognized character: 4\n",
      "Error in line-char 6-102 : Unrecognized character: 6\n",
      "Error in line-char 6-139 : Unrecognized character: 2\n",
      "Error in line-char 6-152 : Unrecognized character: 8\n",
      "Error in line-char 6-154 : Unrecognized character: 8\n",
      "Error in line-char 6-156 : Unrecognized character: 8\n",
      "Error in line-char 6-158 : Unrecognized character: 8\n",
      "Error in line-char 6-160 : Unrecognized character: 8\n",
      "Error in line-char 6-162 : Unrecognized character: 6\n",
      "Error in line-char 6-170 : Unrecognized character: 8\n",
      "Error in line-char 6-214 : Unrecognized character: 2\n",
      "Error in line-char 6-216 : Unrecognized character: 8\n",
      "Error in line-char 6-254 : Unrecognized character: 2\n",
      "Error in line-char 6-262 : Unrecognized character: 0\n",
      "Error in line-char 6-297 : Unrecognized character: 2\n",
      "Error in line-char 6-308 : Unrecognized character: 4\n",
      "Error in line-char 6-310 : Unrecognized character: 8\n",
      "Error in line-char 6-337 : Unrecognized character: 6\n",
      "Error in line-char 6-339 : Unrecognized character: 3\n",
      "Error in line-char 6-343 : Unrecognized character: 8\n",
      "Error in line-char 6-353 : Unrecognized character: 3\n",
      "Error in line-char 6-398 : Unrecognized character: 3\n",
      "Error in line-char 6-442 : Unrecognized character: 4\n",
      "Error in line-char 6-450 : Unrecognized character: 4\n",
      "Error in line-char 6-452 : Unrecognized character: 8\n",
      "Error in line-char 6-459 : Unrecognized character: 8\n",
      "Error in line-char 6-490 : Unrecognized character: 3\n",
      "Error in line-char 6-495 : Unrecognized character: 2\n",
      "Error in line-char 6-497 : Unrecognized character: 6\n",
      "Error in line-char 6-499 : Unrecognized character: 8\n",
      "Error in line-char 6-503 : Unrecognized character: 6\n",
      "Error in line-char 6-505 : Unrecognized character: 6\n",
      "Error in line-char 6-507 : Unrecognized character: 8\n",
      "Error in line-char 6-509 : Unrecognized character: 8\n",
      "Error in line-char 6-541 : Unrecognized character: 6\n",
      "Error in line-char 6-543 : Unrecognized character: 3\n",
      "Error in line-char 6-592 : Unrecognized character: 4\n",
      "Error in line-char 6-594 : Unrecognized character: 2\n",
      "Error in line-char 6-610 : Unrecognized character: 2\n",
      "Error in line-char 6-667 : Unrecognized character: 8\n",
      "Error in line-char 6-669 : Unrecognized character: 8\n",
      "writing MIDI file output.mid\n",
      "Warning in line-char 6-14 : Track 0 Bar 1 has 1/2 units instead of 4\n",
      "Warning in line-char 6-24 : Track 0 Bar 2 has 1 units instead of 4\n",
      "Warning in line-char 6-53 : Track 0 Bar 3 has 13/2 units instead of 4\n",
      "Warning in line-char 6-62 : Track 0 Bar 4 has 2 units instead of 4\n",
      "Warning in line-char 6-75 : Track 0 Bar 5 has 3/2 units instead of 4\n",
      "Warning in line-char 6-83 : Track 0 Bar 6 has 1/2 units instead of 4\n",
      "Warning in line-char 6-168 : Track 0 Bar 8 has 10 units instead of 4\n",
      "Warning in line-char 6-179 : Track 0 Bar 9 has 1/2 units instead of 4\n",
      "Warning in line-char 6-197 : Track 0 Bar 10 has 2 units instead of 4\n",
      "Warning in line-char 6-205 : Track 0 Bar 11 has 1/2 units instead of 4\n",
      "Warning in line-char 6-221 : Track 0 Bar 12 has 3/2 units instead of 4\n",
      "Warning in line-char 6-227 : Track 0 Bar 13 has 1/2 units instead of 4\n",
      "Warning in line-char 6-234 : Track 0 Bar 14 has 1/2 units instead of 4\n",
      "Warning in line-char 6-250 : Track 0 Bar 15 has 5/2 units instead of 4\n",
      "Warning in line-char 6-266 : Track 0 Bar 16 has 11/2 units instead of 4\n",
      "Warning in line-char 6-287 : Track 0 Bar 17 has 13/2 units instead of 4\n",
      "Warning in line-char 6-291 : Track 0 Bar 18 has 1/2 units instead of 4\n",
      "Warning in line-char 6-304 : Track 0 Bar 19 has 1/2 units instead of 4\n",
      "Warning in line-char 6-325 : Track 0 Bar 20 has 3/2 units instead of 4\n",
      "Warning in line-char 6-341 : Track 0 Bar 21 has 2 units instead of 4\n",
      "Warning in line-char 6-363 : Track 0 Bar 22 has 11/2 units instead of 4\n",
      "Warning in line-char 6-372 : Track 0 Bar 23 has 1/2 units instead of 4\n",
      "Warning in line-char 6-378 : Track 0 Bar 24 has 1/2 units instead of 4\n",
      "Warning in line-char 6-404 : Track 0 Bar 25 has 5/2 units instead of 4\n",
      "Warning in line-char 6-428 : Track 0 Bar 26 has 7/2 units instead of 4\n",
      "Warning in line-char 6-474 : Track 0 Bar 27 has 9/2 units instead of 4\n",
      "Warning in line-char 6-518 : Track 0 Bar 28 has 7/2 units instead of 4\n",
      "Warning in line-char 6-526 : Track 0 Bar 29 has 1 units instead of 4\n",
      "Warning in line-char 6-539 : Track 0 Bar 30 has 1 units instead of 4\n",
      "Warning in line-char 6-554 : Track 0 Bar 31 has 1/2 units instead of 4\n",
      "Warning in line-char 6-558 : Track 0 Bar 32 has 1/2 units instead of 4\n",
      "Warning in line-char 6-569 : Track 0 Bar 33 has 1 units instead of 4\n",
      "Warning in line-char 6-579 : Track 0 Bar 34 has 1 units instead of 4\n",
      "Warning in line-char 6-635 : Track 0 Bar 35 has 17 units instead of 4\n",
      "Warning in line-char 6-639 : Track 0 Bar 36 has 1/2 units instead of 4\n",
      "Warning in line-char 6-645 : Track 0 Bar 37 has 1/2 units instead of 4\n",
      "Warning in line-char 6-651 : Track 0 Bar 38 has 1/2 units instead of 4\n",
      "Warning in line-char 6-663 : Track 0 Bar 39 has 1 units instead of 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "abc2midi_path = r\"C:\\Users\\shash\\Downloads\\abcmidi\\abc2midi.exe\"\n",
    "abc_filename = \"cleaned_music.abc\"\n",
    "midi_filename = \"output.mid\"\n",
    "with open(abc_filename, \"w\") as f:\n",
    "    f.write(cleaned_abc)\n",
    "\n",
    "print(f\"Saved '{abc_filename}'\")\n",
    "command = [abc2midi_path, abc_filename, \"-o\", midi_filename]\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(command, capture_output=True, text=True, check=True)\n",
    "    print(\"Conversion Successful!\")\n",
    "    print(result.stdout)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Error during conversion:\")\n",
    "    print(e.stderr)\n",
    "    print(e.stdout)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Could not find the program at: {abc2midi_path}\")\n",
    "    print(\"Please check that abc2midi.exe is actually in that folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bea869-e237-43be-9f5c-b8b3b1610bc4",
   "metadata": {},
   "source": [
    "The next step is to get the music player running for our output mid file generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "794de5e2-c766-41ed-8b05-d382dc3e66dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is your player:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv7357\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv7357_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv7357\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAGgD/UQMHoSAA/1kCAAAA/1gEBAIYCM5g/y8ATVRyawAAA9wA/wMAAOAAQM5gkE9ppzCATwCnMJBKUKcwgEoAAJAkaacwgCQAzmCQRmmnMIBGAACQLlCnMIAuAPYQkEZQpzCARgCBxHCQU1CnMIBTAIHEcJA3aacwgDcAAJBSUKcwgFIAAJAYUKcwgBgAAJBMaacwgEwAzmCQRVCnMIBFAIGdQJBMUKcwgEwAzmCQU1CnMIBTAKcwkCdfpzCAJwCBnUCQTFCnMIBMAKcwkFNQpzCAUwCnMJBSUKcwgFIApzCQRlCnMIBGAACQS1+nMIBLAACQLlCnMIAuAACQS1CnMIBLAACQM1CnMIAzAACQI2mnMIAjAKcwkFFQpzCAUQAAkFJQpzCAUgAAkCZQpzCAJgAAkCJppzCAIgAAkCpppzCAKgCnMJBYUKcwgFgAAJA+aacwgD4AAJAYaacwgBgAAJA5aacwgDkA9hCQGF+nMIAYAACQSmmnMIBKAACQPlCnMIA+AIK7AJBMUKcwgEwAAJAYaacwgBgAAJBTUKcwgFMApzCQQ1CnMIBDAIK7AJAYX6cwgBgApzCQP2mnMIA/AACQKmmnMIAqAACQWFCnMIBYAACQGFCnMIAYAACQSmmnMIBKAACQOVCnMIA5AACQPlCnMIA+AM5gkE9QpzCATwAAkDJQpzCAMgCCk1CQT1CnMIBPAACQGGmnMIAYAACQOWmnMIA5AACQOWmnMIA5AACQHFCnMIAcAACQN1CnMIA3AACQS1CnMIBLAACQNV+nMIA1AACQUWmnMIBRAACQT1CnMIBPAACQI1CnMIAjAACQMlCnMIAyAACQNV+nMIA1AKcwkEVQpzCARQAAkENppzCAQwAAkEpQpzCASgAAkEdQpzCARwAAkFhQpzCAWAAAkEZfpzCARgAAkCpQpzCAKgAAkCZQpzCAJgAAkDJQpzCAMgAAkCJfpzCAIgCnMJA7UKcwgDsAAJAyUKcwgDIAAJBGUKcwgEYApzCQUlCnMIBSAACQHFCnMIAcAACQOmmnMIA6AACQU1CnMIBTAACQOmmnMIA6AACQW1CnMIBbAACQKWmnMIApAACQRWmnMIBFAACQKmmnMIAqAACQM1CnMIAzAACQTWmnMIBNAACQM1CnMIAzAACQLmmnMIAuAACQOVCnMIA5AACQLlCnMIAuAACQG1CnMIAbAIK7AJBIX6cwgEgAgrsAkEdQpzCARwCCuwCQPlCnMIA+AACQOlCnMIA6AACQN1+nMIA3AACQUlCnMIBSAACQT2mnMIBPAACQMmmnMIAyAACQJmmnMIAmAACQOWmnMIA5AACQG1CnMIAbAACQT2mnMIBPAM5g/y8A\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv7357_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv7357_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from music21 import converter, midi\n",
    "mf = converter.parse(\"output.mid\")\n",
    "print(\"Here is your player:\")\n",
    "mf.show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce0d057-4927-4cfa-b2be-e1177b506b75",
   "metadata": {},
   "source": [
    "We are able to get a music running in our player which have some tunes looking good. Although more cleaning and training a better transformer could have given us a better results and is a scope for improvement in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206974e-fcd9-425e-a481-a3eb4bedb642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4015a-99ad-4d87-b5e2-1ed1685d5e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f4654b-6f9f-46ed-bf73-2bd93000fe8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2543b-159d-48ed-a199-c5d2c82e3e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (anaconda-ml-ai)",
   "language": "python",
   "name": "anaconda-ml-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
